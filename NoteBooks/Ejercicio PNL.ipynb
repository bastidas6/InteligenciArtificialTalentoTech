{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5223ffc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Carlos\n",
      "[nltk_data]     Pineda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Carlos\n",
      "[nltk_data]     Pineda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8bf8ea82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Great ambiance, and great food. Indian Accent ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Located as a standalone restaurant at the lodh...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Om sweets restaurant one of the famous place i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>A nice place to have a continental meal with f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>This is the perfect place if you don't wanna s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>Had been to Barbeque Nation to try their elect...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Paasha one of the best and classy place to vis...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>They menu here is rich in continental items an...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>Best restaurant for famous Bengali dishes. The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>Ohh yes finally had the sukkubhai biryani and ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review sentiment\n",
       "309   Great ambiance, and great food. Indian Accent ...  positive\n",
       "313   Located as a standalone restaurant at the lodh...  positive\n",
       "252   Om sweets restaurant one of the famous place i...  positive\n",
       "147   A nice place to have a continental meal with f...  positive\n",
       "1575  This is the perfect place if you don't wanna s...  positive\n",
       "808   Had been to Barbeque Nation to try their elect...  positive\n",
       "467   Paasha one of the best and classy place to vis...  positive\n",
       "1366  They menu here is rich in continental items an...  positive\n",
       "1405  Best restaurant for famous Bengali dishes. The...  positive\n",
       "1091  Ohh yes finally had the sukkubhai biryani and ...  positive"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"reviews.csv\")\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "15500733",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.Series(df.Review.tolist()).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a4aec3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well I\\'m a big fan of Absolute Barbecue but this is my first time in AB\\'s Whitefield branch and the experience was same it\\'s awesomeüòçüòçüòç, it is my friends birthday party üéä and you people make my day, thanks for your courteous service. The celebration gift was very surprised, it\\'s with \"GO GREEN\" concept. Thanks for your amazing work.. Great'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[727]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f2b8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(corpus, ls_permitir):   \n",
    "    corpus_limpio = []\n",
    "    for fila in corpus:\n",
    "        qs = []\n",
    "        for palabra in fila.split():\n",
    "            if palabra not in ls_permitir:\n",
    "                p1 = re.sub(pattern='[^a-zA-Z0-9]',repl=' ',string=palabra)\n",
    "                p1 = p1.lower()\n",
    "                qs.append(p1)\n",
    "            else: \n",
    "                qs.append(palabra)        \n",
    "        corpus_limpio.append(' '.join(qs))\n",
    "    return pd.Series(corpus_limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf72f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_palabras_vacias(corpus):\n",
    "    palabras = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
    "    stop = set(stopwords.words('english'))\n",
    "    for palabra in palabras:\n",
    "        stop.remove(palabra)\n",
    "    corpus = [[x for x in x.split() if x not in stop] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ecc5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematizar(corpus):\n",
    "    lem = WordNetLemmatizer()\n",
    "    corpus = [[lem.lemmatize(x, pos = 'v') for x in x] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "944a1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(corpus, stem_type = None):\n",
    "    if stem_type == 'snowball':\n",
    "        stemmer = SnowballStemmer(language = 'english')\n",
    "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
    "    else :\n",
    "        stemmer = PorterStemmer()\n",
    "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d73b35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_comunes = ['U.S.A', 'Mr.', 'Mrs.', 'D.C.']\n",
    "corpus = limpiar_texto(corpus, palabras_comunes)\n",
    "corpus = remover_palabras_vacias(corpus)\n",
    "#corpus = [[x for x in ] for x in corpus]\n",
    "corpus = [[x for x in oraciones] for oraciones in corpus]\n",
    "corpus = lematizar(corpus)\n",
    "corpus = stem(corpus, 'snowball')    \n",
    "corpus = [' '.join(x) for x in corpus]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd902350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'well big fan absolut barbecu first time ab whitefield branch experi awesom friend birthday parti peopl make day thank courteous servic celebr gift surpris go green concept thank amaz work great'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[727]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedce206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
